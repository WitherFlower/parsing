Puncts = <LGEN> "(<", <RGEN> ">)"
       | <LPAR> "(" , <RPAR> ")"
       | <LT>     "<"
       | <GT>     ">"
       | <LTE>    "<="
       | <GTE>    ">="
       | <LSHIFT> "<<"
       | <RSHIFT> "<<"
       ;

Words  = <ConstIdent> [_]*  [A-Z] [_A-Z0-9]*    &[^a-z]
       | <TypeIdent>  [_]*  [A-Z] [_A-Za-z0-9]*
       | <VarIdent>   [_]*  [a-z] [_A-Za-z0-9]*
       | <Number>     [0-9] [_A-Za-z0-9]*
       ;

VM:
    PUSH / SAVE
    POP  / ROLLBACK
    DROP / FORGET
    CHAR ou STRING (tester la perf)
    CLASS
    BEGINTOKEN
    ENDTOKEN

---

Jumptable pour lexer à la vitesse de la lumière

Puncts   = "(<", "(", "<", "<=", "<<"
Keywords = int, int128
Words = [a-z]

Table :
'(' : instructions for (< and ( sorted in reverse-length alphabetical order
'<' : same as above but <<, <= and < in this order
'[a-hj-z]' : instructions for words like [a-z]
'i' : keywords that start with i, order doesn't matter, need to check that, for every word type they match, they dont match more than the keyword length
      then point to the first word type that matches a single 'i'
other : point to an 'ERROR' instruction that'll either crash the lexer or produce an error token (typeid 0)

---

globalMap:
Map {
    [_] : {
        moreOfTheSame;
        [A-Z]: Map {
            
        }
    }



    '(': Map {
        '<': Done { 0 }
        any: Done { 1 }
    }
}

nextLookup = globalMap;
read '('
nextLookup = globalMap['('];
    | read '<'
    | store Token { 0 }
    | nextLookup = globalMap

    | read any
    | store Token { 1 }
    | nextLookup = globalMap
